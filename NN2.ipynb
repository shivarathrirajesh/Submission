{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quDlLWcAP31q"
   },
   "source": [
    "## MLP for Binary Classification\n",
    "\n",
    "In this lab, you will use the Ionosphere data binary (two-class) classification dataset to demonstrate an MLP for binary classification.\n",
    "\n",
    "This dataset involves predicting whether a structure is in the atmosphere or not given radar returns.\n",
    "\n",
    "The dataset will be downloaded automatically using Pandas, but you can learn more in the links below.\n",
    "\n",
    "[Ionosphere Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv)\n",
    "\n",
    "[Ionosphere Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names)\n",
    "\n",
    "\n",
    "Your task for this is lab is to develop a Keras-based Multi-Layer Perceptron model for this data set. Remember the number of output layers is equal to the number of classes.\n",
    "\n",
    "Following we have provided some piece of code to you while you need to complete the rest of the code on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6086ipzNP31q"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "# Your code to import read_csv class from pandas\n",
    "from pandas import read_csv\n",
    "# Your code to import train_test_split class from sklearn. \n",
    "#Follow link https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7755rFn_iDRj"
   },
   "source": [
    "# Read the dataset from the path below. Store the data in a pandas dataframe named 'df'\n",
    "\n",
    "Link to API - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "058u-qkXP31r"
   },
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
    "\n",
    "# Your code to read the csv from the above path.\n",
    "df = read_csv(path, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG3n2OHrjQsG"
   },
   "source": [
    "See the sample dataset. Print few rows of the dataset. Use dataframe.head() method.\n",
    "\n",
    "Link to API:  https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jx3JTj4sfUIt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print first few rows of the dataset.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo8Siqyxfhj7"
   },
   "source": [
    "Print the basic info of the dataset. Use dataframe.info() from pandas library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VgN9rYV_fiag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 351 entries, 0 to 350\n",
      "Data columns (total 35 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       351 non-null    int64  \n",
      " 1   1       351 non-null    int64  \n",
      " 2   2       351 non-null    float64\n",
      " 3   3       351 non-null    float64\n",
      " 4   4       351 non-null    float64\n",
      " 5   5       351 non-null    float64\n",
      " 6   6       351 non-null    float64\n",
      " 7   7       351 non-null    float64\n",
      " 8   8       351 non-null    float64\n",
      " 9   9       351 non-null    float64\n",
      " 10  10      351 non-null    float64\n",
      " 11  11      351 non-null    float64\n",
      " 12  12      351 non-null    float64\n",
      " 13  13      351 non-null    float64\n",
      " 14  14      351 non-null    float64\n",
      " 15  15      351 non-null    float64\n",
      " 16  16      351 non-null    float64\n",
      " 17  17      351 non-null    float64\n",
      " 18  18      351 non-null    float64\n",
      " 19  19      351 non-null    float64\n",
      " 20  20      351 non-null    float64\n",
      " 21  21      351 non-null    float64\n",
      " 22  22      351 non-null    float64\n",
      " 23  23      351 non-null    float64\n",
      " 24  24      351 non-null    float64\n",
      " 25  25      351 non-null    float64\n",
      " 26  26      351 non-null    float64\n",
      " 27  27      351 non-null    float64\n",
      " 28  28      351 non-null    float64\n",
      " 29  29      351 non-null    float64\n",
      " 30  30      351 non-null    float64\n",
      " 31  31      351 non-null    float64\n",
      " 32  32      351 non-null    float64\n",
      " 33  33      351 non-null    float64\n",
      " 34  34      351 non-null    object \n",
      "dtypes: float64(32), int64(2), object(1)\n",
      "memory usage: 96.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code to print information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX_YFAb4kdl4"
   },
   "source": [
    "Print the shape of the dataframe. Select suitable API call from the pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rlfCOssvf44O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to print the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aekdoY2zkxU4"
   },
   "source": [
    "# Separate the input and output from the dataframe. Input is all columns besides last column. Output is the last column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_5bh8al2P31s"
   },
   "outputs": [],
   "source": [
    "X = df.values[:, :-1]\n",
    "# Your code to get y - Hint y = df.values[:, some parameters]\n",
    "y = df.values[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7y3GhJDloqk"
   },
   "source": [
    "We have converted everthing in X to 'float' and the letters in column y to the numbers in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qVtPf2F9lg17"
   },
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ_aY4H3l9bI"
   },
   "source": [
    "Printing the genral information of the X and y in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BWBOMrBigew9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.       0.       0.99539 ... -0.54487  0.18641 -0.453  ]\n",
      " [ 1.       0.       1.      ... -0.06288 -0.13738 -0.02447]\n",
      " [ 1.       0.       1.      ... -0.2418   0.56045 -0.38238]\n",
      " ...\n",
      " [ 1.       0.       0.94701 ...  0.00442  0.92697 -0.00577]\n",
      " [ 1.       0.       0.90608 ... -0.03757  0.87403 -0.16243]\n",
      " [ 1.       0.       0.8471  ... -0.06678  0.85764 -0.06151]]\n",
      "[1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(351, 34)\n",
      "(351,)\n"
     ]
    }
   ],
   "source": [
    "# Your code to print X\n",
    "print(X)\n",
    "\n",
    "# Your code to print y\n",
    "print(y)\n",
    "\n",
    "# your code to print shape of X. Remember X is a numpy array\n",
    "print(X.shape)\n",
    "\n",
    "# your code to print shape of y. Remember y is a numpy array\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9ltrLLqmkgW"
   },
   "source": [
    "* Separate X and y into training and test set with a ratio of your choice.\n",
    "* Print the shapes of the resulting arrays.\n",
    "* Get the number of features from X_train. Remember the number of features are the number of inputs.\n",
    "\n",
    "Use sklearn train_test_split class.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-CjFJcAMP31s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 34) (116, 34) (235,) (116,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to separate the data into trauning and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# Your code to print shape of X_train\n",
    "# Your code to print shape of X_test\n",
    "# Your code to print shape of y_train\n",
    "# Your code to print shape of X_test\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQdqYXJ9pqzC"
   },
   "source": [
    "# Creating a Multi-layer Perceptron using Keras.\n",
    "We have added first and last layers. Create the hidden layers of your choise.\n",
    "You can chose any number of hidden layers and activation function of your chose\n",
    "https://keras.io/api/layers/core_layers/dense/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hhTE3u-_P31t"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_features,)))\n",
    "\n",
    "\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "#\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 10)                350       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 447 (1.75 KB)\n",
      "Trainable params: 447 (1.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (235, 34)\n",
      "X_test shape: (116, 34)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NtBU922rH67"
   },
   "source": [
    "In the next cell, we trained the above neural network model and tested its accuracy. As this concept has still not benn covered in the class, just run the code to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "krgB1SuRP31t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\Murali\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Murali\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 1s 3ms/step - loss: 0.6911 - accuracy: 0.5277\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.7319\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.7489\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.7532\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7532\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7489\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7574\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7532\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7574\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7745\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7787\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7787\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7830\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7872\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8000\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8000\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8128\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8170\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8255\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8468\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8553\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8553\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8681\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8723\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8723\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8723\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8723\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8851\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8894\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8979\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.9021\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.9021\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9021\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.9021\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9064\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2632 - accuracy: 0.9191\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9277\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9319\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2430 - accuracy: 0.9362\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2372 - accuracy: 0.9404\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9404\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9404\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9447\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9447\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9489\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9489\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9489\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9489\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9489\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1878 - accuracy: 0.9489\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 565us/step - loss: 0.1830 - accuracy: 0.9489\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9489\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.9489\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 704us/step - loss: 0.1723 - accuracy: 0.9489\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1709 - accuracy: 0.9489\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1658 - accuracy: 0.9532\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1624 - accuracy: 0.9489\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1595 - accuracy: 0.9489\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1563 - accuracy: 0.9574\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1532 - accuracy: 0.9574\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1506 - accuracy: 0.9574\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1476 - accuracy: 0.9574\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9574\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9617\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9617\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9617\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9617\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9617\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9617\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9617\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9617\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9617\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9660\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9660\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9660\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.9702\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9702\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9702\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9702\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9702\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9702\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9702\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9702\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9702\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9702\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9702\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0955 - accuracy: 0.9702\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0942 - accuracy: 0.9745\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0931 - accuracy: 0.9745\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0918 - accuracy: 0.9745\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0901 - accuracy: 0.9745\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0896 - accuracy: 0.9745\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0886 - accuracy: 0.9745\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0864 - accuracy: 0.9745\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 145us/step - loss: 0.0865 - accuracy: 0.9745\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9745\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9745\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9745\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9745\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9745\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0789 - accuracy: 0.9745\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0780 - accuracy: 0.9745\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0772 - accuracy: 0.9787\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 147us/step - loss: 0.0764 - accuracy: 0.9787\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9787\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9787\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9787\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.9787\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9787\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9787\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9787\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9787\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9787\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9787\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9787\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0664 - accuracy: 0.9787\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9787\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9787\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9787\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9787\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9787\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0633 - accuracy: 0.9787\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0612 - accuracy: 0.9787\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0606 - accuracy: 0.9787\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 134us/step - loss: 0.0603 - accuracy: 0.9787\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9787\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9787\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9787\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9787\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9787\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9787\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9787\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 893us/step - loss: 0.0554 - accuracy: 0.9787\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0553 - accuracy: 0.9830\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0569 - accuracy: 0.9915\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9872\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9830\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9830\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9830\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0520 - accuracy: 0.9830\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0514 - accuracy: 0.9872\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9872\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0505 - accuracy: 0.9915\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0504 - accuracy: 0.9915\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0495 - accuracy: 0.9915\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 127us/step - loss: 0.0491 - accuracy: 0.9915\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9915\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9915\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9915\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9224\n",
      "Test Accuracy: 0.922\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "Accuracy = history_dict['accuracy']\n",
    "plt.figure(num=1, figsize=(15,7))\n",
    "plt.plot(Accuracy, 'bo', label='Training accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='gelu', input_shape=(n_features,)))\n",
    "\n",
    "\n",
    "#\n",
    "# Add as many layers with activation functions of your choice\n",
    "#\n",
    "model.add(Dense(8, activation='gelu'))\n",
    "model.add(Dense(5, activation='gelu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 10)                350       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 45        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 489 (1.91 KB)\n",
      "Trainable params: 489 (1.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5745\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6638\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 804us/step - loss: 0.6709 - accuracy: 0.7319\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.7404\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.7319\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7277\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7234\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7234\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7234\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 689us/step - loss: 0.5355 - accuracy: 0.7277\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7362\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7489\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7489\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7532\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7660\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7872\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8213\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8383\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8511\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8596\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8638\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 254us/step - loss: 0.3672 - accuracy: 0.8766\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.3536 - accuracy: 0.8851\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8851\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8851\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8894\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8936\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.8936\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.9021\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9064\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.9149\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.9149\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9149\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.9191\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.2209 - accuracy: 0.9234\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9234\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9234\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9234\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9319\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9277\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9362\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9404\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9447\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 166us/step - loss: 0.1736 - accuracy: 0.9447\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1705 - accuracy: 0.9447\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9532\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9532\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9532\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9489\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9532\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9532\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9574\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1477 - accuracy: 0.9532\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9574\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1426 - accuracy: 0.9574\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9574\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9617\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9617\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9617\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.1334 - accuracy: 0.9574\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9574\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9574\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9574\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9617\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9617\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9574\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9617\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9617\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9660\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9617\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 149us/step - loss: 0.1161 - accuracy: 0.9617\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9617\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9617\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1114 - accuracy: 0.9660\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9660\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9660\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9617\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 51us/step - loss: 0.1082 - accuracy: 0.9617\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9702\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9617\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9617\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.9617\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9660\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9660\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9702\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9745\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9745\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9702\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9745\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9745\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0918 - accuracy: 0.9702\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9745\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9787\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9787\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0871 - accuracy: 0.9787\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0862 - accuracy: 0.9787\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0851 - accuracy: 0.9787\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0836 - accuracy: 0.9787\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0837 - accuracy: 0.9787\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0816 - accuracy: 0.9787\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 152us/step - loss: 0.0805 - accuracy: 0.9787\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9787\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9787\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9787\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9787\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9787\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9787\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9787\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9787\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9787\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9787\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9787\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9787\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9787\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9787\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9787\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9787\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9787\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9787\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9787\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9787\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9787\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9787\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0620 - accuracy: 0.9787\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9787\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9787\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9787\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9787\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9830\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9830\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9830\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9787\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 0s/step - loss: 0.0564 - accuracy: 0.9830\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9872\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9872\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9830\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9872\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9872\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9872\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9830\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9872\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9872\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9872\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9872\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9872\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9830\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9872\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9872\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9872\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8966\n",
      "Test Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ReYGy_jsCh0"
   },
   "source": [
    "** How much accuracy have you got? Compare the accuracy with your peers. **\n",
    "** Now, change your model and activation function to get the better accuracy as compared to your peers **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmeq5l1edZPg"
   },
   "source": [
    "## **Important:** Document in your lab logbook the accuracy of the improved model. Do not include any code or explanations in your lab logbook. Simply record the accuracy. For example, if the obtained accuracy is 0.98, then enter \"0.98\" in your lab logbook.\n",
    "\n",
    "## In addition to the accuracy, also document the output of the neural network as provided in Task 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFNL8fY2rd41"
   },
   "source": [
    "\n",
    "Next, we have provided the code to predict on an unknown value.\n",
    "We will cover these concepts later in the class. For now, just run the code to see the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXV7gQRAP31u",
    "outputId": "a5092aea-3cad-4009-de83-956caa73ecba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "Predicted: 0.994\n"
     ]
    }
   ],
   "source": [
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,\n",
    "       0.83398,-0.37708,1,0.03760,0.85243,-0.17755,\n",
    "       0.59755,-0.44945,0.60536,-0.38223,0.84356,\n",
    "       -0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,\n",
    "       -0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,\n",
    "       -0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])\n",
    "print('Predicted: %.3f' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNFK4kV9P31u"
   },
   "source": [
    "### Try out the same model with Keras Functional models!\n",
    "Refer to [Keras](https://keras.io/) for more details and tutorials for the same."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
